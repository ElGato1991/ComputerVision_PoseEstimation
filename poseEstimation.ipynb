{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d824bf7",
   "metadata": {},
   "source": [
    "# Pose Estimation with camera in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97915e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    r = model(frame, verbose=False)[0]\n",
    "    cv2.imshow(\"pose\", r.plot())\n",
    "    if cv2.waitKey(1) == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71fa36",
   "metadata": {},
   "source": [
    "# Showing only Keypoints\n",
    "\n",
    "Hinweis: Die Kopf-Keypoints (COCO-Indices 0–4: Nase, linkes/rechtes Auge, linkes/rechtes Ohr) werden vor dem Zeichnen ausgeblendet, indem ihre Konfidenz auf 0 gesetzt wird.\n",
    "\n",
    "Gruppen-Definitionen (COCO 17 KP):\n",
    "- head: [0–4]\n",
    "- shoulders: [5,6]\n",
    "- arms: [5–10]\n",
    "- wrists: [9,10]\n",
    "- hips: [11,12]\n",
    "- legs: [11–16]\n",
    "- knees: [13,14]\n",
    "- ankles: [15,16]\n",
    "- torso: [5,6,11,12]\n",
    "- all: [0–16]\n",
    "\n",
    "Steuerung: Passe in der folgenden Zelle die Variable HIDE_GROUPS an, z. B. [\"head\"], [\"head\",\"arms\"], [\"legs\"], [\"all\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fadf3b",
   "metadata": {},
   "source": [
    "# Hand- und Finger-Keypoints (21 KPs)\n",
    "\n",
    "Wir erweitern die Visualisierung um Hand- und Finger-Keypoints mit einem separaten Hand-Pose-Modell (`yolo11n-pose -hand.pt`).\n",
    "\n",
    "- Pro Hand werden 21 Keypoints erwartet (0 = Handgelenk, dann je 4 Punkte für Daumen/Zeige-/Mittel-/Ring-/Kleiner Finger).\n",
    "- Finger-Skelette (Standard-Konvention, ggf. je nach Modell leicht unterschiedlich):\n",
    "  - Daumen: 0–1–2–3–4\n",
    "  - Zeigefinger: 0–5–6–7–8\n",
    "  - Mittelfinger: 0–9–10–11–12\n",
    "  - Ringfinger: 0–13–14–15–16\n",
    "  - Kleiner Finger: 0–17–18–19–20\n",
    "- Die Hand-Keypoints werden farbig gezeichnet (jeder Finger eigene Farbe) und auf denselben schwarzen Canvas gelegt wie die Körper-Keypoints.\n",
    "\n",
    "Hinweise\n",
    "- Die Datei hat ein Leerzeichen im Namen (`yolo11n-pose -hand.pt`). Das ist ok, der Pfad bleibt ein normaler String.\n",
    "- Performance: Zwei Modelle pro Frame (Körper + Hände) sind rechenintensiver. Bei Bedarf die Auflösung/FPS reduzieren oder `conf` erhöhen.\n",
    "- Steuerung: Über `DRAW_HANDS`, `HAND_MIN_CONF` und `HAND_MODEL_PATH` kann das Verhalten angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb23fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyvirtualcam opened: OBS Virtual Camera\n",
      "Controls:\n",
      "  Press '1' to switch to camera\n",
      "  Press '2' to switch to desktop screen\n",
      "  Press 'ESC' to quit\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "# optional: pyvirtualcam for virtual webcam output\n",
    "try:\n",
    "    import pyvirtualcam\n",
    "    from pyvirtualcam import PixelFormat\n",
    "    HAVE_PYVIRTUALCAM = True\n",
    "except Exception:\n",
    "    HAVE_PYVIRTUALCAM = False\n",
    "\n",
    "# optional: mss for desktop screen capture\n",
    "try:\n",
    "    from mss import mss\n",
    "    HAVE_MSS = True\n",
    "except Exception:\n",
    "    HAVE_MSS = False\n",
    "    print(\"mss not installed. Install with: pip install mss\")\n",
    "\n",
    "# -------------------- configurable options --------------------\n",
    "BODY_MODEL_PATH = \"yolov8n-pose.pt\"\n",
    "HAND_MODEL_PATH = r\"C:\\Users\\adria\\Documents\\HandPose\\runs\\hand\\overnight_run\\weights\\best.pt\"\n",
    "CAM_INDEX = 1\n",
    "\n",
    "# Toggle & Schwellenwerte\n",
    "DRAW_BODY = False       # nur Hände anzeigen (Körper nicht rendern)\n",
    "DRAW_HANDS = True\n",
    "USE_WRIST_CROPS = True   # schneller: Hände nur um die Handgelenke herum inferieren\n",
    "HAND_MIN_CONF = 0.25     # Keypoint-Konfidenz für Zeichnen der Handpunkte\n",
    "HAND_PRED_CONF = 0.25    # Inferenz-Konfidenz für das Handmodell\n",
    "BODY_MIN_CONF = 0.30     # Keypoint-Konfidenz für Körper (z. B. Ellbogen/Handgelenk)\n",
    "\n",
    "# Wrist-Crop Parameter\n",
    "HAND_CROP_SCALE = 2.0    # Seitenlänge ~ scale * Unterarmlänge\n",
    "HAND_CROP_MIN = 96\n",
    "HAND_CROP_MAX = 320\n",
    "\n",
    "# -------------------- load models & camera --------------------\n",
    "body_model = YOLO(BODY_MODEL_PATH)\n",
    "hand_model = YOLO(HAND_MODEL_PATH) if DRAW_HANDS else None\n",
    "\n",
    "cap = cv2.VideoCapture(CAM_INDEX)\n",
    "if not cap.isOpened():\n",
    "    # fallback to camera 0 if 1 is not available\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"No camera available\")\n",
    "\n",
    "# grab a first frame to determine size for the virtual camera\n",
    "ok, frame = cap.read()\n",
    "if not ok:\n",
    "    cap.release()\n",
    "    raise RuntimeError(\"Can't read from camera\")\n",
    "\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# Initialize screen capture\n",
    "sct = mss() if HAVE_MSS else None\n",
    "screen_monitor = None\n",
    "if sct:\n",
    "    # Get the primary monitor\n",
    "    screen_monitor = sct.monitors[1]  # monitor 0 is all monitors, 1 is primary\n",
    "\n",
    "# Source mode: 'camera' or 'desktop'\n",
    "source_mode = 'camera'\n",
    "\n",
    "cam = None\n",
    "if HAVE_PYVIRTUALCAM:\n",
    "    try:\n",
    "        # use RGB pixel format (pyvirtualcam expects RGB frames)\n",
    "        cam = pyvirtualcam.Camera(width=width, height=height, fps=20, fmt=PixelFormat.RGB)\n",
    "        print('pyvirtualcam opened:', cam.device)\n",
    "    except Exception as e:\n",
    "        print('Failed to open virtual camera:', e)\n",
    "        cam = None\n",
    "\n",
    "# COCO 17 keypoints: names and index groups\n",
    "KEYPOINT_NAMES = [\n",
    "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\",\n",
    "    \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\",\n",
    "    \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
    "]\n",
    "\n",
    "GROUP_IDXS = {\n",
    "    # head and facial\n",
    "    \"head\": [0, 1, 2, 3, 4],\n",
    "    # upper body\n",
    "    \"shoulders\": [5, 6],\n",
    "    \"arms\": [5, 6, 7, 8, 9, 10],\n",
    "    \"wrists\": [9, 10],\n",
    "    # lower body\n",
    "    \"hips\": [11, 12],\n",
    "    \"legs\": [11, 12, 13, 14, 15, 16],\n",
    "    \"knees\": [13, 14],\n",
    "    \"ankles\": [15, 16],\n",
    "    # torso rectangle (shoulders + hips)\n",
    "    \"torso\": [5, 6, 11, 12],\n",
    "    # convenience\n",
    "    \"all\": list(range(17)),\n",
    "}\n",
    "\n",
    "# Which groups to hide (zero confidence before drawing)\n",
    "# Examples: [\"head\"], [\"head\", \"arms\"], [\"legs\"], [\"all\"]\n",
    "HIDE_GROUPS = [\"\"]\n",
    "\n",
    "def merged_idxs(groups):\n",
    "    s = set()\n",
    "    for g in groups:\n",
    "        s.update(GROUP_IDXS.get(g, []))\n",
    "    return sorted(s)\n",
    "\n",
    "HIDE_IDXS = merged_idxs(HIDE_GROUPS)\n",
    "\n",
    "# ---------- drawing helpers ----------\n",
    "# Ensure points are within image bounds for drawing\n",
    "def _clip_point(pt, w, h):\n",
    "    x, y = int(round(pt[0])), int(round(pt[1]))\n",
    "    return (max(0, min(w - 1, x)), max(0, min(h - 1, y)))\n",
    "\n",
    "def draw_cube(img, center, u, wv, side, depth_scale=0.6, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Draws a faux-3D cube at 'center' using oriented basis vectors u (arm direction) and\n",
    "    wv (its image-plane perpendicular). 'side' is the base square side length in pixels.\n",
    "    depth_scale controls the offset between the two squares.\n",
    "    \"\"\"\n",
    "    # normalize basis just in case\n",
    "    u = np.asarray(u, dtype=float)\n",
    "    wv = np.asarray(wv, dtype=float)\n",
    "    nu = np.linalg.norm(u) or 1.0\n",
    "    nw = np.linalg.norm(wv) or 1.0\n",
    "    u /= nu\n",
    "    wv /= nw\n",
    "\n",
    "    a = side / 2.0\n",
    "    c = np.asarray(center, dtype=float)\n",
    "    # base square corners (counter-clockwise)\n",
    "    c0 = c + (-a) * u + (-a) * wv\n",
    "    c1 = c + ( a) * u + (-a) * wv\n",
    "    c2 = c + ( a) * u + ( a) * wv\n",
    "    c3 = c + (-a) * u + ( a) * wv\n",
    "    base = [c0, c1, c2, c3]\n",
    "\n",
    "    # top square offset (simple isometric-ish offset)\n",
    "    off = (u + wv) * (a * depth_scale)\n",
    "    top = [p + off for p in base]\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    base_i = [_clip_point(p, w, h) for p in base]\n",
    "    top_i  = [_clip_point(p, w, h) for p in top]\n",
    "\n",
    "    # draw squares\n",
    "    for pts in (base_i, top_i):\n",
    "        for i in range(4):\n",
    "            p1, p2 = pts[i], pts[(i + 1) % 4]\n",
    "            cv2.line(img, p1, p2, color, thickness)\n",
    "    # connect corresponding corners\n",
    "    for i in range(4):\n",
    "        cv2.line(img, base_i[i], top_i[i], color, thickness)\n",
    "\n",
    "# ----- Hand drawing: 21 keypoints, 5 fingers -----\n",
    "# Finger definitions (common 21-KP scheme):\n",
    "THUMB  = [0, 1, 2, 3, 4]\n",
    "INDEX  = [0, 5, 6, 7, 8]\n",
    "MIDDLE = [0, 9, 10, 11, 12]\n",
    "RING   = [0, 13, 14, 15, 16]\n",
    "PINKY  = [0, 17, 18, 19, 20]\n",
    "HAND_FINGERS = [THUMB, INDEX, MIDDLE, RING, PINKY]\n",
    "FINGER_COLORS = [\n",
    "    (0, 255, 255),   # thumb - cyan\n",
    "    (0, 255, 0),     # index - green\n",
    "    (255, 0, 255),   # middle - magenta\n",
    "    (255, 255, 0),   # ring - yellow\n",
    "    (0, 128, 255),   # pinky - orange-ish\n",
    "]\n",
    "\n",
    "def draw_hand_skeleton(img, kp_any, min_conf=HAND_MIN_CONF):\n",
    "    \"\"\"Draws hand keypoints and finger bones with colored lines.\n",
    "    Accepts either a torch.Tensor (N,3) or a NumPy array (N,3), where N can be 21 (hands) or others.\n",
    "    \"\"\"\n",
    "    # coerce to numpy\n",
    "    if hasattr(kp_any, 'detach'):\n",
    "        pts = kp_any[:, :2].detach().cpu().numpy()\n",
    "        if kp_any.shape[1] >= 3:\n",
    "            conf = kp_any[:, 2].detach().cpu().numpy()\n",
    "        else:\n",
    "            conf = np.ones((pts.shape[0],), dtype=np.float32)\n",
    "    else:\n",
    "        arr = np.asarray(kp_any)\n",
    "        pts = arr[:, :2]\n",
    "        if arr.shape[1] >= 3:\n",
    "            conf = arr[:, 2]\n",
    "        else:\n",
    "            conf = np.ones((pts.shape[0],), dtype=np.float32)\n",
    "\n",
    "    n = pts.shape[0]\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # draw keypoints\n",
    "    for i, (x, y) in enumerate(pts):\n",
    "        if i >= n:\n",
    "            break\n",
    "        if conf[i] < min_conf:\n",
    "            continue\n",
    "        xi, yi = _clip_point((x, y), w, h)\n",
    "        cv2.circle(img, (xi, yi), 3, (0, 200, 255), -1)  # small dot\n",
    "\n",
    "    # draw finger lines (only indices inside range)\n",
    "    for fi, finger in enumerate(HAND_FINGERS):\n",
    "        color = FINGER_COLORS[fi % len(FINGER_COLORS)]\n",
    "        # keep only valid indices\n",
    "        valid = [j for j in finger if 0 <= j < n]\n",
    "        for a, b in zip(valid[:-1], valid[1:]):\n",
    "            if conf[a] >= min_conf and conf[b] >= min_conf:\n",
    "                p1 = _clip_point(pts[a], w, h)\n",
    "                p2 = _clip_point(pts[b], w, h)\n",
    "                cv2.line(img, p1, p2, color, 2)\n",
    "\n",
    "\n",
    "def _square_roi(center_xy, side, w, h):\n",
    "    \"\"\"Return clipped integer ROI (x0,y0,x1,y1) for a square centered at center_xy.\"\"\"\n",
    "    cx, cy = center_xy\n",
    "    a = side / 2.0\n",
    "    x0 = int(round(cx - a)); x1 = int(round(cx + a))\n",
    "    y0 = int(round(cy - a)); y1 = int(round(cy + a))\n",
    "    x0 = max(0, min(w - 1, x0)); x1 = max(0, min(w, x1))\n",
    "    y0 = max(0, min(h - 1, y0)); y1 = max(0, min(h, y1))\n",
    "    if x1 <= x0 or y1 <= y0:\n",
    "        return None\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "print(\"Controls:\")\n",
    "print(\"  Press '1' to switch to camera\")\n",
    "print(\"  Press '2' to switch to desktop screen\")\n",
    "print(\"  Press 'ESC' to quit\")\n",
    "\n",
    "while True:\n",
    "    # Capture frame based on current source mode\n",
    "    if source_mode == 'camera':\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "    elif source_mode == 'desktop':\n",
    "        if sct and screen_monitor:\n",
    "            # Capture desktop screen\n",
    "            screenshot = sct.grab(screen_monitor)\n",
    "            frame = np.array(screenshot)\n",
    "            # Convert BGRA to BGR\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "            # Resize to match camera resolution for consistency\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "            ok = True\n",
    "        else:\n",
    "            print(\"Desktop capture not available (mss not installed)\")\n",
    "            source_mode = 'camera'\n",
    "            continue\n",
    "    else:\n",
    "        ok = False\n",
    "\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # black canvas for drawing\n",
    "    canvas = np.zeros_like(frame)\n",
    "    ann = Annotator(canvas, line_width=2)\n",
    "\n",
    "    # --------- BODY POSE ---------\n",
    "    res_body = body_model(frame, verbose=False)[0]\n",
    "\n",
    "    # Prepare wrist/elbow landmarks (for crops), optionally draw body\n",
    "    left_wrist = right_wrist = None\n",
    "    left_elbow = right_elbow = None\n",
    "\n",
    "    if hasattr(res_body, 'keypoints') and res_body.keypoints is not None:\n",
    "        for kp in res_body.keypoints.data:  # torch.Tensor shape (17,3)\n",
    "            # extract wrists/elbows (first person only for speed)\n",
    "            if left_wrist is None:\n",
    "                lx, ly, lc = kp[9].tolist()   # left_wrist\n",
    "                rx, ry, rc = kp[10].tolist()  # right_wrist\n",
    "                lex, ley, lec = kp[7].tolist()  # left_elbow\n",
    "                rex, rey, rec = kp[8].tolist()  # right_elbow\n",
    "                left_wrist = (lx, ly, lc)\n",
    "                right_wrist = (rx, ry, rc)\n",
    "                left_elbow = (lex, ley, lec)\n",
    "                right_elbow = (rex, rey, rec)\n",
    "\n",
    "            if DRAW_BODY:\n",
    "                kpf = kp.clone()\n",
    "                if HIDE_IDXS:\n",
    "                    kpf[HIDE_IDXS, 2] = 0.0  # hide selected groups by zeroing confidence\n",
    "                ann.kpts(kpf, radius=3)      # draw remaining kpts + bones\n",
    "\n",
    "                # draw cube on left arm (elbow->wrist)\n",
    "                ex, ey, ec = kp[7].tolist()\n",
    "                wx, wy, wc = kp[9].tolist()\n",
    "                if ec >= BODY_MIN_CONF and wc >= BODY_MIN_CONF:\n",
    "                    v = np.array([wx - ex, wy - ey], dtype=float)\n",
    "                    L = np.linalg.norm(v)\n",
    "                    if L > 1.0:\n",
    "                        u = v / L\n",
    "                        wv = np.array([-u[1], u[0]], dtype=float)  # 90° rotate in image plane\n",
    "                        center = ((ex + wx) / 2.0, (ey + wy) / 2.0)\n",
    "                        side = float(np.clip(0.6 * L, 20.0, 80.0))\n",
    "                        draw_cube(canvas, center, u, wv, side, depth_scale=0.7, color=(0, 255, 255), thickness=2)\n",
    "\n",
    "    # --------- HAND POSE (optional) ---------\n",
    "    if DRAW_HANDS and hand_model is not None:\n",
    "        if USE_WRIST_CROPS and left_wrist is not None and right_wrist is not None:\n",
    "            h, w = frame.shape[:2]\n",
    "            crops = []\n",
    "            # left\n",
    "            lx, ly, lc = left_wrist\n",
    "            if lc >= BODY_MIN_CONF:\n",
    "                if left_elbow is not None:\n",
    "                    lex, ley, lec = left_elbow\n",
    "                    forearm = np.linalg.norm([lx - lex, ly - ley]) if lec >= BODY_MIN_CONF else 80.0\n",
    "                else:\n",
    "                    forearm = 80.0\n",
    "                side = float(np.clip(HAND_CROP_SCALE * forearm, HAND_CROP_MIN, HAND_CROP_MAX))\n",
    "                roi = _square_roi((lx, ly), side, w, h)\n",
    "                if roi is not None:\n",
    "                    crops.append(roi)\n",
    "            # right\n",
    "            rx, ry, rc = right_wrist\n",
    "            if rc >= BODY_MIN_CONF:\n",
    "                if right_elbow is not None:\n",
    "                    rex, rey, rec = right_elbow\n",
    "                    forearm = np.linalg.norm([rx - rex, ry - rey]) if rec >= BODY_MIN_CONF else 80.0\n",
    "                else:\n",
    "                    forearm = 80.0\n",
    "                side = float(np.clip(HAND_CROP_SCALE * forearm, HAND_CROP_MIN, HAND_CROP_MAX))\n",
    "                roi = _square_roi((rx, ry), side, w, h)\n",
    "                if roi is not None:\n",
    "                    crops.append(roi)\n",
    "\n",
    "            for (x0, y0, x1, y1) in crops:\n",
    "                roi_img = frame[y0:y1, x0:x1]\n",
    "                if roi_img.size == 0:\n",
    "                    continue\n",
    "                res_hand = hand_model(roi_img, conf=HAND_PRED_CONF, verbose=False)[0]\n",
    "                if hasattr(res_hand, 'keypoints') and res_hand.keypoints is not None:\n",
    "                    for hkpt in res_hand.keypoints.data:  # (N,3) where N may be 21\n",
    "                        hk = hkpt.detach().cpu().numpy().copy()\n",
    "                        hk[:, 0] += x0\n",
    "                        hk[:, 1] += y0\n",
    "                        draw_hand_skeleton(canvas, hk, min_conf=HAND_MIN_CONF)\n",
    "        else:\n",
    "            # full-frame hand inference\n",
    "            res_hand = hand_model(frame, conf=HAND_PRED_CONF, verbose=False)[0]\n",
    "            if hasattr(res_hand, 'keypoints') and res_hand.keypoints is not None:\n",
    "                for hkpt in res_hand.keypoints.data:  # (N,3)\n",
    "                    draw_hand_skeleton(canvas, hkpt, min_conf=HAND_MIN_CONF)\n",
    "\n",
    "    out = ann.result()\n",
    "\n",
    "    # Add source indicator text\n",
    "    text = f\"Source: {source_mode.upper()}\"\n",
    "    cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # send to virtual camera (pyvirtualcam expects RGB order)\n",
    "    if HAVE_PYVIRTUALCAM and cam is not None:\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "            cam.send(rgb)\n",
    "            cam.sleep_until_next_frame()\n",
    "        except Exception as e:\n",
    "            print('pyvirtualcam send failed:', e)\n",
    "            HAVE_PYVIRTUALCAM = False\n",
    "\n",
    "    # local preview\n",
    "    cv2.imshow(\"pose\", out)\n",
    "    \n",
    "    # Handle keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC\n",
    "        break\n",
    "    elif key == ord('1'):\n",
    "        source_mode = 'camera'\n",
    "        print(\"Switched to camera\")\n",
    "    elif key == ord('2'):\n",
    "        if HAVE_MSS:\n",
    "            source_mode = 'desktop'\n",
    "            print(\"Switched to desktop screen\")\n",
    "        else:\n",
    "            print(\"Desktop capture not available. Install mss: pip install mss\")\n",
    "\n",
    "cap.release()\n",
    "if cam is not None:\n",
    "    cam.close()\n",
    "if sct is not None:\n",
    "    sct.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
